{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE+5LgzZR2/OT+tYxtzEfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeoZ666/classroom_NLP/blob/main/NLP_exp6_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dictionary of known lemma forms\n",
        "lemma_dict = {\n",
        "    \"running\": \"run\",\n",
        "    \"ran\": \"run\",\n",
        "    \"eaten\": \"eat\",\n",
        "    \"ate\": \"eat\",\n",
        "    \"better\": \"good\",\n",
        "    \"worse\": \"bad\",\n",
        "    \"happier\": \"happy\",\n",
        "    \"happiest\": \"happy\",\n",
        "    \"cats\": \"cat\",\n",
        "    \"watches\": \"watch\"\n",
        "}\n",
        "\n",
        "# Simplified POS tagging function\n",
        "def pos_tag(word):\n",
        "    # Heuristic rules for POS tagging based on suffixes\n",
        "    if word.endswith('ing'):\n",
        "        return 'VBG'  # Present participle/gerund\n",
        "    if word.endswith('ed'):\n",
        "        return 'VBD'  # Past tense\n",
        "    if word.endswith('es') or word.endswith('s'):\n",
        "        return 'NNS'  # Plural noun\n",
        "    if word in [\"better\", \"worse\", \"happier\", \"happiest\"]:\n",
        "        return 'JJR'  # Comparative/Superlative adjective\n",
        "    return 'NN'  # Default to noun\n",
        "\n",
        "# Function to lemmatize a word with POS tagging\n",
        "def lemmatize(word):\n",
        "    # Step 1: Check if the word is in the lemma dictionary\n",
        "    if word in lemma_dict:\n",
        "        return lemma_dict[word]\n",
        "    \n",
        "    # Step 2: Perform POS tagging\n",
        "    pos = pos_tag(word)\n",
        "    \n",
        "    # Step 3: Apply lemmatization rules based on POS\n",
        "    if pos == 'VBG' or pos == 'VBD':  # Verbs\n",
        "        if word.endswith('ing') and len(word) > 4:\n",
        "            return word[:-3]\n",
        "        if word.endswith('ed') and len(word) > 3:\n",
        "            return word[:-2]\n",
        "    elif pos == 'NNS':  # Plural nouns\n",
        "        if word.endswith('es'):\n",
        "            return word[:-2]\n",
        "        if word.endswith('s') and len(word) > 2:\n",
        "            return word[:-1]\n",
        "    elif pos == 'JJR':  # Comparative/Superlative adjectives\n",
        "        if word.endswith('er') or word.endswith('est'):\n",
        "            return word[:-2]\n",
        "    \n",
        "    # Step 4: If no rules apply, return the word as is\n",
        "    return word\n",
        "\n",
        "# Test cases\n",
        "words = [\"running\", \"ran\", \"eaten\", \"ate\", \"better\", \"happier\", \"cats\", \"watches\", \"played\", \"thinking\"]\n",
        "lemmatized_words = [lemmatize(word) for word in words]\n",
        "\n",
        "# Print the results in a table format\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Original Word\", \"Lemmatized Word\", \"Part of Speech\"]\n",
        "\n",
        "for word in words:\n",
        "    lemma = lemmatize(word)\n",
        "    pos = pos_tag(word)\n",
        "    table.add_row([word, lemma, pos])\n",
        "\n",
        "print(table)\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The happy cats were thinking about running and playing in the garden.\"\n",
        "lemmatized_sentence = \" \".join([lemmatize(word) for word in sentence.split()])\n",
        "print(f\"Original Sentence: {sentence}\")\n",
        "print(f\"Lemmatized Sentence: {lemmatized_sentence}\")\n"
      ],
      "metadata": {
        "id": "3vI4TsCto-B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "# Step 2: Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Step 3: Define a sample paragraph\n",
        "paragraph = \"\"\"The Faludi Ferenc Jesuit Academy launched in 2022 a new dialogue between faith and science through a series of eight “mirror” conferences held between January and June. The novelty of this dialogue is that it brought to the same table representatives of religious institutions and men and women with a scientific background to debate on selected topics relevant both for the protection of creation and sustainable development. The following topics were selected for social reflection and debate: partnership and dialogue, green economy, sustainable lifestyle, climate change, poverty, sustainable communities, environmental change, social justice. The original approach of these series of mirror conferences, entitled “Forum for an Integral Ecology,” was embedded in the format of all the conferences, so that each selected topic was addressed by two specialists, one presenting the religious angle and the other the scientific point of view. Interactive debates open to the public, people attending in situ as well as those participating on line, followed the keynote presentations. Through this dynamic, we tried to generate a social reflection on the created world and sustainable development.\n",
        "The result of this first round of debates was the book entitled Integral Ecology. Dialogue between faith and science in the spirit of Laudato si’, published by the Jesuit Printing House in Budapest. It includes 16 reflections on the eight major topics selected for the forum. Each chapter of the publication offers many ways of finding authentic individual and collective answers to the multiple socio-economic and ecological crises, in the specific cultural and territorial context of Hungary.\n",
        "The need to supplement the three classical dimensions of sustainable development (the social, economic, and environmental dimensions) with a spiritual dimension, adding specific Christian values to each sustainable development goal, as defined in the 2030 Agenda of the United Nations. Sustainable Development Goals without clearly assumed or agreed upon values cannot mobilize individuals or lead to collective actions. This “supplement” will help provide clearly defined orientation for institutions. Faith provides, in these circumstances, an immanent motivation for the authentic enforcement of the protection of creation by giving us an internal moral guidance. This spiritual dimension of sustainability may lead to the ecological conversion stressed in the papal encyclical Laudato si’.\n",
        "\n",
        "Ignatian spirituality could play a special role in giving shape to the spiritual dimension of sustainability, specifically through the Spiritual Exercises. The Ignatian method and orientations may help to distinguish between ecological sins and ecological virtues. The strengthening of the relationship between God, humanity, and nature may help in a meaningful ecological conversion process.\"\"\"\n",
        "\n",
        "# Step 4: Tokenize and POS Tag the paragraph\n",
        "tokens = word_tokenize(paragraph)\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Step 5: Count the occurrences of each POS tag\n",
        "tag_counts = Counter(tag for word, tag in tagged_tokens)\n",
        "\n",
        "# Display the counts\n",
        "tag_counts\n",
        "\n",
        "# Define POS categories for display\n",
        "pos_categories = {\n",
        "    'VERB': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
        "    'NOUN': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
        "    'ADJ': ['JJ', 'JJR', 'JJS'],\n",
        "    'ADV': ['RB', 'RBR', 'RBS'],\n",
        "    'CONJ': ['CC'],\n",
        "    'PRON': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
        "    'DET': ['DT'],\n",
        "    'ADP': ['IN'],\n",
        "    'PART': ['RP'],\n",
        "    'NUM': ['CD']\n",
        "}\n",
        "\n",
        "# Initialize counts\n",
        "pos_summary = {category: 0 for category in pos_categories}\n",
        "\n",
        "# Aggregate counts by POS category\n",
        "for pos_category, tags in pos_categories.items():\n",
        "    pos_summary[pos_category] = sum(count for tag, count in tag_counts.items() if tag in tags)\n",
        "\n",
        "# Display the summarized counts\n",
        "pos_summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChKlDbacolT9",
        "outputId": "f13aa170-e453-4ed2-e392-6591c911f657"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'VERB': 46,\n",
              " 'NOUN': 142,\n",
              " 'ADJ': 64,\n",
              " 'ADV': 6,\n",
              " 'CONJ': 19,\n",
              " 'PRON': 4,\n",
              " 'DET': 59,\n",
              " 'ADP': 62,\n",
              " 'PART': 0,\n",
              " 'NUM': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define a sample paragraph\n",
        "paragraph = \"\"\"The Faludi Ferenc Jesuit Academy launched in 2022 a new dialogue between faith and science through a series of eight “mirror.\"\"\"\n",
        "\n",
        "# Tokenize and POS Tag the paragraph\n",
        "tokens = word_tokenize(paragraph)\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Define POS categories for classification\n",
        "pos_categories = {\n",
        "    'VERB': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
        "    'NOUN': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
        "    'ADJ': ['JJ', 'JJR', 'JJS'],\n",
        "    'ADV': ['RB', 'RBR', 'RBS'],\n",
        "    'CONJ': ['CC'],\n",
        "    'PRON': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
        "    'DET': ['DT'],\n",
        "    'ADP': ['IN'],\n",
        "    'PART': ['RP'],\n",
        "    'NUM': ['CD']\n",
        "}\n",
        "\n",
        "# Function to classify POS tags\n",
        "def classify_pos(tag):\n",
        "    for category, tags in pos_categories.items():\n",
        "        if tag in tags:\n",
        "            return category\n",
        "    return 'OTHER'  # For tags not classified in the provided categories\n",
        "\n",
        "# Classify each word\n",
        "classified_words = [{'word': word, 'pos': classify_pos(tag)} for word, tag in tagged_tokens]\n",
        "\n",
        "# Save to JSON file\n",
        "with open('classified_words.json', 'w') as json_file:\n",
        "    json.dump(classified_words, json_file, indent=4)\n",
        "\n",
        "# Display the classified words (for verification)\n",
        "classified_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8cc-QElqz_R",
        "outputId": "1dec5dea-6b93-4aa0-dcd0-5c2424595f2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'word': 'The', 'pos': 'DET'},\n",
              " {'word': 'Faludi', 'pos': 'NOUN'},\n",
              " {'word': 'Ferenc', 'pos': 'NOUN'},\n",
              " {'word': 'Jesuit', 'pos': 'NOUN'},\n",
              " {'word': 'Academy', 'pos': 'NOUN'},\n",
              " {'word': 'launched', 'pos': 'VERB'},\n",
              " {'word': 'in', 'pos': 'ADP'},\n",
              " {'word': '2022', 'pos': 'NUM'},\n",
              " {'word': 'a', 'pos': 'DET'},\n",
              " {'word': 'new', 'pos': 'ADJ'},\n",
              " {'word': 'dialogue', 'pos': 'NOUN'},\n",
              " {'word': 'between', 'pos': 'ADP'},\n",
              " {'word': 'faith', 'pos': 'NOUN'},\n",
              " {'word': 'and', 'pos': 'CONJ'},\n",
              " {'word': 'science', 'pos': 'NOUN'},\n",
              " {'word': 'through', 'pos': 'ADP'},\n",
              " {'word': 'a', 'pos': 'DET'},\n",
              " {'word': 'series', 'pos': 'NOUN'},\n",
              " {'word': 'of', 'pos': 'ADP'},\n",
              " {'word': 'eight', 'pos': 'NUM'},\n",
              " {'word': '“', 'pos': 'NOUN'},\n",
              " {'word': 'mirror', 'pos': 'NOUN'},\n",
              " {'word': '.', 'pos': 'OTHER'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}